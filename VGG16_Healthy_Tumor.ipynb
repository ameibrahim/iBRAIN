{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:33.282933Z",
     "iopub.status.busy": "2024-01-27T05:40:33.282502Z",
     "iopub.status.idle": "2024-01-27T05:40:33.288963Z",
     "shell.execute_reply": "2024-01-27T05:40:33.287882Z",
     "shell.execute_reply.started": "2024-01-27T05:40:33.282901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:33.645573Z",
     "iopub.status.busy": "2024-01-27T05:40:33.644499Z",
     "iopub.status.idle": "2024-01-27T05:40:33.657806Z",
     "shell.execute_reply": "2024-01-27T05:40:33.65669Z",
     "shell.execute_reply.started": "2024-01-27T05:40:33.645533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'test', 'train']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDir = \"./datasetBinaryTumor/\"\n",
    "os.listdir(baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:39.493652Z",
     "iopub.status.busy": "2024-01-27T05:40:39.492824Z",
     "iopub.status.idle": "2024-01-27T05:40:39.499317Z",
     "shell.execute_reply": "2024-01-27T05:40:39.498382Z",
     "shell.execute_reply.started": "2024-01-27T05:40:39.493614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 files belonging to 2 classes.\n",
      "Using 5120 files for training.\n",
      "Found 6400 files belonging to 2 classes.\n",
      "Using 1280 files for validation.\n",
      "Found 1600 files belonging to 2 classes.\n",
      "Images shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # Use categorical for multi-class classification\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,  # Reserve 20% of data for validation\n",
    "    subset=\"training\",     # Load training subset\n",
    "    seed=42                # Ensure reproducibility\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Test dataset (assuming separate directory for test data)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False  # No shuffling for test set\n",
    ")\n",
    "\n",
    "train_ds.class_names\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:39.512484Z",
     "iopub.status.busy": "2024-01-27T05:40:39.512099Z",
     "iopub.status.idle": "2024-01-27T05:40:39.587788Z",
     "shell.execute_reply": "2024-01-27T05:40:39.586853Z",
     "shell.execute_reply.started": "2024-01-27T05:40:39.512453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(data_augmentation(x, training=True)), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MobileNet CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:39.589265Z",
     "iopub.status.busy": "2024-01-27T05:40:39.588957Z",
     "iopub.status.idle": "2024-01-27T05:40:40.395126Z",
     "shell.execute_reply": "2024-01-27T05:40:40.394178Z",
     "shell.execute_reply.started": "2024-01-27T05:40:39.589238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vgg_16 = tf.keras.applications.VGG16(input_shape = (224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:40.828834Z",
     "iopub.status.busy": "2024-01-27T05:40:40.828509Z",
     "iopub.status.idle": "2024-01-27T05:40:41.154055Z",
     "shell.execute_reply": "2024-01-27T05:40:41.153208Z",
     "shell.execute_reply.started": "2024-01-27T05:40:40.828808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model with explicit input\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),  # üîπ Explicit input layer\n",
    "    vgg_16,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  # Hidden layer\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation='softmax')  # Final classification layer\n",
    "])\n",
    "\n",
    "# Call model to initialize input shape\n",
    "model.build(input_shape=(None, 224, 224, 3))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:42.039186Z",
     "iopub.status.busy": "2024-01-27T05:40:42.038861Z",
     "iopub.status.idle": "2024-01-27T05:40:42.054866Z",
     "shell.execute_reply": "2024-01-27T05:40:42.054056Z",
     "shell.execute_reply.started": "2024-01-27T05:40:42.039161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',  # Suitable for binary classification\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T05:40:44.660479Z",
     "iopub.status.busy": "2024-01-27T05:40:44.660077Z",
     "iopub.status.idle": "2024-01-27T06:00:18.764284Z",
     "shell.execute_reply": "2024-01-27T06:00:18.763448Z",
     "shell.execute_reply.started": "2024-01-27T05:40:44.660446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1171s\u001b[0m 7s/step - accuracy: 0.8654 - loss: 0.4880 - val_accuracy: 0.9930 - val_loss: 0.3882\n",
      "Epoch 2/2\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 3s/step - accuracy: 0.9569 - loss: 0.3922 - val_accuracy: 0.9898 - val_loss: 0.3696\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=20, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T06:00:30.159807Z",
     "iopub.status.busy": "2024-01-27T06:00:30.159545Z",
     "iopub.status.idle": "2024-01-27T06:00:30.561884Z",
     "shell.execute_reply": "2024-01-27T06:00:30.560877Z",
     "shell.execute_reply.started": "2024-01-27T06:00:30.159785Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"VGG16_tumornotumor.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "def plot_metrics(history, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "plot_metrics(history, 'output/graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test data...\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 460ms/step - accuracy: 0.9945 - loss: 0.1366\n",
      "Test Loss: 0.3596\n",
      "Test Accuracy: 0.9887\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 551ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, jaccard_score, log_loss, fbeta_score\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Ensure the results directory exists\n",
    "results_dir = \"binaryVGG16TUMORNOTUMOR\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save training metrics (loss and accuracy)\n",
    "def save_training_metrics(history, results_dir):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save training and validation metrics in a text file\n",
    "    with open(os.path.join(results_dir, \"training_validation_metrics.txt\"), \"w\") as f:\n",
    "        f.write(\"Training and Validation Metrics Per Epoch\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for i, (acc, val_acc, loss, val_loss) in enumerate(zip(\n",
    "            history.history['accuracy'], history.history['val_accuracy'], \n",
    "            history.history['loss'], history.history['val_loss']\n",
    "        )):\n",
    "            f.write(f\"Epoch {i+1}:\\n\")\n",
    "            f.write(f\"  Training Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}\\n\")\n",
    "            f.write(f\"  Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Generate ROC curve\n",
    "def save_roc_curve(y_true, y_probs, results_dir):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"roc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_metrics(y_true, y_pred, y_probs, results_dir, class_names):\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Sensitivity = Recall\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "\n",
    "    # Compute additional metrics\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average='binary')\n",
    "    logloss = log_loss(y_true, y_probs)\n",
    "    fbeta = fbeta_score(y_true, y_pred, beta=0.5)  # Example for F0.5-score\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"classification_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall (Sensitivity): {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "        f.write(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"Jaccard Index (IoU): {jaccard:.4f}\\n\")\n",
    "        f.write(f\"Log Loss: {logloss:.4f}\\n\")\n",
    "        f.write(f\"F0.5-Score: {fbeta:.4f}\\n\")\n",
    "# Evaluate and save all metrics\n",
    "def save_model_metrics(model, test_ds, results_dir, class_names):\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model on test data...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save test metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"testing_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Generate predictions\n",
    "    y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "    y_probs = model.predict(test_ds)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_true, axis=1)  # Assuming one-hot encoded labels\n",
    "\n",
    "    # Save confusion matrix\n",
    "    save_confusion_matrix(y_true, y_pred, class_names, results_dir)\n",
    "\n",
    "    # Save ROC curve\n",
    "    if len(class_names) == 2:  # Only valid for binary classification\n",
    "        save_roc_curve(y_true, y_probs[:, 1], results_dir)\n",
    "\n",
    "    # Save classification metrics\n",
    "    save_classification_metrics(y_true, y_pred, y_probs[:, 1], results_dir, class_names)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `history` is the history object returned by `model.fit()`\n",
    "# and `test_ds` is your test dataset\n",
    "save_training_metrics(history, results_dir)\n",
    "save_model_metrics(model, test_ds, results_dir, class_names=[\"notumor\", \"tumor\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2763641,
     "sourceId": 4774750,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
